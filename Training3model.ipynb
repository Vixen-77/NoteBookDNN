{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d79bfee1",
   "metadata": {},
   "source": [
    "installez tf2onnx le package pour la conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e89732",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8853dc2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "drive.mount('/content/drive')\n",
    "# Charger le dataset complet normalis&\n",
    "df_train = pd.read_csv('/content/drive/MyDrive/train_normalized.csv')\n",
    "df_val = pd.read_csv('/content/drive/MyDrive/val_normalized.csv')\n",
    "df_test = pd.read_csv('/content/drive/MyDrive/test_normalized.csv')\n",
    "df_train.info()\n",
    "df_train.describe()\n",
    "df_train.head()\n",
    "\n",
    "df_val.info()\n",
    "df_val.describe()\n",
    "df_val.head()\n",
    "\n",
    "df_test.info()\n",
    "df_test.describe()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "import joblib\n",
    "drive.mount('/content/drive')\n",
    "# Charger les fichiers déjà normalisés\n",
    "df_train = pd.read_csv('/content/drive/MyDrive/train_normalized.csv')\n",
    "df_val = pd.read_csv('/content/drive/MyDrive/val_normalized.csv')\n",
    "\n",
    "# Séparation des features (X) et de la cible (y) pour les deux ensembles\n",
    "X_train = df_train.drop('Risk_Category', axis=1)\n",
    "y_train = df_train['Risk_Category']\n",
    "X_val = df_val.drop('Risk_Category', axis=1)\n",
    "y_val = df_val['Risk_Category']\n",
    "\n",
    "# Définir l'architecture du modèle\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(14,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Couche de sortie\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Afficher le résumé du modèle\n",
    "model.summary()\n",
    "\n",
    "# Définir le chemin de sauvegarde du modèle\n",
    "checkpoint_path = \"/content/drive/MyDrive/IAPFE/model1_checkpoint.keras\"\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',  # maintenant on surveille val_accuracy !\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entraîner le modèle en incluant la validation\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),  # Utilisation du fichier de validation séparé\n",
    "    callbacks=[model_checkpoint]\n",
    ")\n",
    "\n",
    "# Charger le meilleur modèle sauvegardé\n",
    "model = tf.keras.models.load_model(checkpoint_path)\n",
    "\n",
    "# Tracer la courbe d'apprentissage\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "epochs = range(1, len(train_accuracy) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_accuracy, 'r-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b-', label='Validation Accuracy')\n",
    "plt.title('Courbe d\\'apprentissage')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473da18",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Tracer la courbe de perte (loss)\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_loss, 'r-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b-', label='Validation Loss')\n",
    "plt.title('Courbe de perte (Loss)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d605d779",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CODE TRES PRESIEUX\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "from google.colab import drive\n",
    "\n",
    "# Monter Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Charger le modèle Keras Sequential\n",
    "seq_model = tf.keras.models.load_model('/content/drive/MyDrive/IAPFE/model1_checkpoint.keras')\n",
    "\n",
    "# Créer un modèle fonctionnel pour éviter l'erreur .output_names\n",
    "inputs = tf.keras.Input(shape=(14,), name=\"input\")  # adapte selon ton dataset\n",
    "outputs = seq_model(inputs)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Conversion vers ONNX\n",
    "spec = (tf.TensorSpec([None, 14], tf.float32, name=\"input\"),)\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(\n",
    "    model,\n",
    "    input_signature=spec,\n",
    "    opset=13\n",
    ")\n",
    "\n",
    "# Sauvegarde\n",
    "with open(\"/content/drive/MyDrive/IAPFE/IOThealth1.0.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(\"✅ Modèle converti avec succès en ONNX !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8341ce5f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "import joblib\n",
    "drive.mount('/content/drive')\n",
    "# Charger les fichiers déjà normalisés\n",
    "df_train = pd.read_csv('/content/drive/MyDrive/train_normalized.csv')\n",
    "df_val = pd.read_csv('/content/drive/MyDrive/val_normalized.csv')\n",
    "\n",
    "# Séparation des features (X) et de la cible (y) pour les deux ensembles\n",
    "X_train = df_train.drop('Risk_Category', axis=1)\n",
    "y_train = df_train['Risk_Category']\n",
    "X_val = df_val.drop('Risk_Category', axis=1)\n",
    "y_val = df_val['Risk_Category']\n",
    "\n",
    "# Définir l'architecture du modèle\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(14,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Couche de sortie\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Afficher le résumé du modèle\n",
    "model.summary()\n",
    "\n",
    "# Définir le chemin de sauvegarde du modèle\n",
    "checkpoint_path = \"/content/drive/MyDrive/IAPFE/model2_checkpoint.keras\"\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',  # maintenant on surveille val_accuracy !\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entraîner le modèle en incluant la validation\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),  # Utilisation du fichier de validation séparé\n",
    "    callbacks=[model_checkpoint]\n",
    ")\n",
    "\n",
    "# Charger le meilleur modèle sauvegardé\n",
    "model = tf.keras.models.load_model(checkpoint_path)\n",
    "\n",
    "# Tracer la courbe d'apprentissage\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "epochs = range(1, len(train_accuracy) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_accuracy, 'r-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b-', label='Validation Accuracy')\n",
    "plt.title('Courbe d\\'apprentissage')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad550279",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Tracer la courbe de perte (loss)\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_loss, 'r-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b-', label='Validation Loss')\n",
    "plt.title('Courbe de perte (Loss)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a1f45",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CODE TRES PRESIEUX\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "from google.colab import drive\n",
    "\n",
    "# Monter Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Charger le modèle Keras Sequential\n",
    "seq_model = tf.keras.models.load_model('/content/drive/MyDrive/IAPFE/model2_checkpoint.keras')\n",
    "\n",
    "# Créer un modèle fonctionnel pour éviter l'erreur .output_names\n",
    "inputs = tf.keras.Input(shape=(14,), name=\"input\")  # adapte selon ton dataset\n",
    "outputs = seq_model(inputs)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Conversion vers ONNX\n",
    "spec = (tf.TensorSpec([None, 14], tf.float32, name=\"input\"),)\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(\n",
    "    model,\n",
    "    input_signature=spec,\n",
    "    opset=13\n",
    ")\n",
    "\n",
    "# Sauvegarde\n",
    "with open(\"/content/drive/MyDrive/IAPFE/IOThealth2.0.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(\"✅ Modèle converti avec succès en ONNX !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fe14a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "import joblib\n",
    "drive.mount('/content/drive')\n",
    "# Charger les fichiers déjà normalisés\n",
    "df_train = pd.read_csv('/content/drive/MyDrive/train_normalized.csv')\n",
    "df_val = pd.read_csv('/content/drive/MyDrive/val_normalized.csv')\n",
    "\n",
    "# Séparation des features (X) et de la cible (y) pour les deux ensembles\n",
    "X_train = df_train.drop('Risk_Category', axis=1)\n",
    "y_train = df_train['Risk_Category']\n",
    "X_val = df_val.drop('Risk_Category', axis=1)\n",
    "y_val = df_val['Risk_Category']\n",
    "\n",
    "# Définir l'architecture du modèle\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(14,)),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.27),\n",
    "    tf.keras.layers.Dense(12, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.27),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Couche de sortie\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Afficher le résumé du modèle\n",
    "model.summary()\n",
    "\n",
    "# Définir le chemin de sauvegarde du modèle\n",
    "checkpoint_path = \"/content/drive/MyDrive/IAPFE/model3_checkpoint.keras\"\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',  # maintenant on surveille val_accuracy !\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entraîner le modèle en incluant la validation\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),  # Utilisation du fichier de validation séparé\n",
    "    callbacks=[model_checkpoint]\n",
    ")\n",
    "\n",
    "# Charger le meilleur modèle sauvegardé\n",
    "model = tf.keras.models.load_model(checkpoint_path)\n",
    "\n",
    "# Tracer la courbe d'apprentissage\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "epochs = range(1, len(train_accuracy) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_accuracy, 'r-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b-', label='Validation Accuracy')\n",
    "plt.title('Courbe d\\'apprentissage')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3987079",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Tracer la courbe de perte (loss)\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_loss, 'r-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b-', label='Validation Loss')\n",
    "plt.title('Courbe de perte (Loss)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd0ae7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CODE TRES PRESIEUX\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "from google.colab import drive\n",
    "\n",
    "# Monter Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Charger le modèle Keras Sequential\n",
    "seq_model = tf.keras.models.load_model('/content/drive/MyDrive/IAPFE/model3_checkpoint.keras')\n",
    "\n",
    "# Créer un modèle fonctionnel pour éviter l'erreur .output_names\n",
    "inputs = tf.keras.Input(shape=(14,), name=\"input\")  # adapte selon ton dataset\n",
    "outputs = seq_model(inputs)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Conversion vers ONNX\n",
    "spec = (tf.TensorSpec([None, 14], tf.float32, name=\"input\"),)\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(\n",
    "    model,\n",
    "    input_signature=spec,\n",
    "    opset=13\n",
    ")\n",
    "\n",
    "# Sauvegarde\n",
    "with open(\"/content/drive/MyDrive/IAPFE/IOThealth3.0.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(\"✅ Modèle converti avec succès en ONNX !\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
